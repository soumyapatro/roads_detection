{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full explanation of the code, visit http://ataspinar.com/2017/12/04/using-convolutional-neural-networks-to-detect-features-in-sattelite-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy import ndimage\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#We are using owslib to download images from a WMS Service\n",
    "#install with 'pip install owslib'\n",
    "\n",
    "import owslib\n",
    "\n",
    "from owslib.wms import WebMapService\n",
    "\n",
    "#pyshp is necessary for loading and saving shapefiles\n",
    "#install with 'pip install pyshp'\n",
    "import shapefile\n",
    "\n",
    "# Install opencv with 'pip install opencv-python'\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = 90000\n",
    "y_min = 427000\n",
    "dx, dy = 200, 200\n",
    "no_tiles_x = 100\n",
    "no_tiles_y = 100\n",
    "total_no_tiles = no_tiles_x * no_tiles_y\n",
    "\n",
    "x_max = x_min + no_tiles_x * dx\n",
    "y_max = y_min + no_tiles_y * dy\n",
    "bounding_box = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "TILE_FOLDER = \"./datasets/image_tiles_200/\"\n",
    "URL_TILES = \"https://geodata.nationaalgeoregister.nl/luchtfoto/rgb/wms?request=GetCapabilities\"\n",
    "\n",
    "URL_SHP = 'https://www.rijkswaterstaat.nl/apps/geoservices/geodata/dmc/nwb-wegen/geogegevens/shapefile/Nederland_totaal/01-08-2017/Wegvakken/Wegvakken.shp'\n",
    "URL_PRF = 'https://www.rijkswaterstaat.nl/apps/geoservices/geodata/dmc/nwb-wegen/geogegevens/shapefile/Nederland_totaal/01-08-2017/Wegvakken/Wegvakken.prj'\n",
    "URL_DBF = 'https://www.rijkswaterstaat.nl/apps/geoservices/geodata/dmc/nwb-wegen/geogegevens/shapefile/Nederland_totaal/01-08-2017/Wegvakken/Wegvakken.dbf'\n",
    "URL_SHX = 'https://www.rijkswaterstaat.nl/apps/geoservices/geodata/dmc/nwb-wegen/geogegevens/shapefile/Nederland_totaal/01-08-2017/Wegvakken/Wegvakken.shx'\n",
    "\n",
    "URLS_SHAPEFILES = [URL_SHP, URL_PRF, URL_DBF, URL_SHX]\n",
    "\n",
    "DATA_FOLDER = \"./data/nwb_wegvakken/\"\n",
    "\n",
    "json_filename = DATA_FOLDER + '2017_09_wegvakken.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Downloading the image tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "#Skip if you already have the image tiles. Will take ~ 2hours.\n",
    "wms = WebMapService(URL_TILES, version='1.1.1')\n",
    "\n",
    "if not os.path.exists(TILE_FOLDER):\n",
    "    os.makedirs(TILE_FOLDER)\n",
    "\n",
    "for ii in range(0,25):\n",
    "    print(ii)\n",
    "    for jj in range(0,no_tiles_y):\n",
    "        ll_x_ = x_min + ii*dx\n",
    "        ll_y_ = y_min + jj*dy\n",
    "        bbox = (ll_x_, ll_y_, ll_x_ + dx, ll_y_ + dy) \n",
    "        img = wms.getmap(layers=['Actueel_ortho25'], srs='EPSG:28992', bbox=bbox, size=(256, 256), format='image/jpeg', transparent=True)\n",
    "        filename = \"{}{}_{}_{}_{}.jpg\".format(TILE_FOLDER, bbox[0], bbox[1], bbox[2], bbox[3])\n",
    "        out = open(filename, 'wb')\n",
    "        out.write(img.read())\n",
    "        out.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. Downloading the shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Skip if you already have the shapefiles. Will take ~ 1hour.\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "\n",
    "for url in URLS_SHAPEFILES:\n",
    "    filename = url.split('/')[-1]\n",
    "    print(\"Downloading file {}\".format(filename))\n",
    "    r = requests.get(url, stream=True)\n",
    "    if r.status_code == 200:\n",
    "        with open(DATA_FOLDER + filename, 'wb') as f:\n",
    "            r.raw.decode_content = True\n",
    "            shutil.copyfileobj(r.raw, f)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading shapefile and converting to (GEO)Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Skip if conversion already done and \"json_filename\" already saved\n",
    "def json_serial(obj):\n",
    "    \"\"\"JSON serializer for objects not serializable by default json code\"\"\"\n",
    "\n",
    "    if isinstance(obj, (datetime, date)):\n",
    "        serial = obj.isoformat()\n",
    "        return serial\n",
    "    if isinstance(obj, bytes):\n",
    "        return {'__class__': 'bytes',\n",
    "                '__value__': list(obj)}\n",
    "    raise TypeError (\"Type %s not serializable\" % type(obj))\n",
    "\n",
    "reader = shapefile.Reader(DATA_FOLDER + 'Wegvakken.shp')\n",
    "fields = reader.fields[1:]\n",
    "field_names = [field[0] for field in fields]\n",
    "\n",
    "buffer = []\n",
    "for sr in reader.shapeRecords()[:500000]:\n",
    "    atr = dict(zip(field_names, sr.record))\n",
    "    geom = sr.shape.__geo_interface__\n",
    "    buffer.append(dict(type=\"Feature\", geometry=geom, properties=atr)) \n",
    "\n",
    "\n",
    "json_file = open(json_filename, \"w\")\n",
    "json_file.write(json.dumps({\"type\": \"FeatureCollection\", \"features\": buffer}, indent=2, default=json_serial) + \"\\n\")\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Declaring some variables and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_roadtype = {\n",
    "    \"G\": 'Gemeente',\n",
    "    \"R\": 'Rijk',\n",
    "    \"P\": 'Provincie',\n",
    "    \"W\": 'Waterschap',\n",
    "    'T': 'Andere wegbeheerder',\n",
    "    '' : 'leeg'\n",
    "}\n",
    "\n",
    "dict_roadtype_to_color = {\n",
    "    \"G\": 'red',\n",
    "    \"R\": 'blue',\n",
    "    \"P\": 'green',\n",
    "    \"W\": 'magenta',\n",
    "    'T': 'yellow',\n",
    "    '' : 'leeg'\n",
    "}\n",
    "\n",
    "FEATURES_KEY = 'features'\n",
    "PROPERTIES_KEY = 'properties'\n",
    "GEOMETRY_KEY = 'geometry'\n",
    "COORDINATES_KEY = 'coordinates'\n",
    "WEGSOORT_KEY = 'WEGBEHSRT'\n",
    "\n",
    "MINIMUM_NO_POINTS_PER_TILE = 4\n",
    "POINTS_PER_METER = 10 # Changed by David from 0.1\n",
    "\n",
    "INPUT_FOLDER_TILES = './datasets/image_tiles_200/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(d1, d2, coordinates, rtype):\n",
    "    coordinate_ll_x = int((coordinates[0] // dx)*dx)\n",
    "    coordinate_ll_y = int((coordinates[1] // dy)*dy)\n",
    "    coordinate_ur_x = int((coordinates[0] // dx)*dx + dx)\n",
    "    coordinate_ur_y = int((coordinates[1] // dy)*dy + dy)\n",
    "    tile = \"{}_{}_{}_{}.jpg\".format(coordinate_ll_x, coordinate_ll_y, coordinate_ur_x, coordinate_ur_y)\n",
    "    \n",
    "    rel_coord_x = (coordinates[0] - coordinate_ll_x) / dx\n",
    "    rel_coord_y = (coordinates[1] - coordinate_ll_y) / dy\n",
    "    value = (rtype, rel_coord_x, rel_coord_y)\n",
    "    d1[tile].append(value)\n",
    "    d2[rtype].add(tile)\n",
    "\n",
    "def coord_is_in_bb(coord, bb):\n",
    "    x_min = bb[0]\n",
    "    y_min = bb[1]\n",
    "    x_max = bb[2]\n",
    "    y_max = bb[3]\n",
    "    return coord[0] > x_min and coord[0] < x_max and coord[1] > y_min and coord[1] < y_max\n",
    "\n",
    "def retrieve_roadtype(elem):\n",
    "    return elem[PROPERTIES_KEY][WEGSOORT_KEY]\n",
    "   \n",
    "def retrieve_coordinates(elem):\n",
    "    return elem[GEOMETRY_KEY][COORDINATES_KEY]\n",
    "\n",
    "def eucledian_distance(p1, p2):\n",
    "    diff = np.array(p2)-np.array(p1)\n",
    "    return np.linalg.norm(diff)\n",
    "\n",
    "def calculate_intermediate_points(p1, p2, no_points):\n",
    "    dx = (p2[0] - p1[0]) / (no_points + 1)\n",
    "    dy = (p2[1] - p1[1]) / (no_points + 1)\n",
    "    return [[p1[0] + i * dx, p1[1] +  i * dy] for i in range(1, no_points+1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Map contents of shapefile to the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_wegvakken = json_filename\n",
    "dict_wegvakken = json.load(open(filename_wegvakken))[FEATURES_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tile_contents = defaultdict(list)\n",
    "d_roadtype_tiles = defaultdict(set)\n",
    "    \n",
    "for elem in dict_wegvakken:\n",
    "    coordinates = retrieve_coordinates(elem)\n",
    "    rtype = retrieve_roadtype(elem)\n",
    "    coordinates_in_bb = [coord for coord in coordinates if coord_is_in_bb(coord, bounding_box)]\n",
    "    if len(coordinates_in_bb)==1:\n",
    "        coord = coordinates_in_bb[0]\n",
    "        add_to_dict(d_tile_contents, d_roadtype_tiles, coord, rtype)\n",
    "    if len(coordinates_in_bb)>1:\n",
    "        add_to_dict(d_tile_contents, d_roadtype_tiles, coordinates_in_bb[0], rtype)\n",
    "        for ii in range(1,len(coordinates_in_bb)):\n",
    "            previous_coord = coordinates_in_bb[ii-1]\n",
    "            coord = coordinates_in_bb[ii]\n",
    "            add_to_dict(d_tile_contents, d_roadtype_tiles, coord, rtype)\n",
    "            \n",
    "            dist = eucledian_distance(previous_coord, coord)\n",
    "            no_intermediate_points = int(dist*POINTS_PER_METER)           \n",
    "            intermediate_coordinates = calculate_intermediate_points(previous_coord, coord, no_intermediate_points)\n",
    "            for intermediate_coord in intermediate_coordinates:\n",
    "                add_to_dict(d_tile_contents, d_roadtype_tiles, intermediate_coord, rtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added by David:\n",
    "# 4a. Create dictionary of road-pixel matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary\n",
    "d_road_pixels = {}\n",
    "\n",
    "# Loop through all image tiles\n",
    "for ii in range(0,no_tiles_x):\n",
    "    for jj in range(0,no_tiles_y):\n",
    "        ll_x = x_min + ii*dx\n",
    "        ll_y = y_min + jj*dy\n",
    "        ur_x = ll_x + dx\n",
    "        ur_y = ll_y + dy\n",
    "        tile = \"{}_{}_{}_{}.jpg\".format(ll_x, ll_y, ur_x, ur_y)\n",
    "        filename = INPUT_FOLDER_TILES + tile   \n",
    "        # Extract list of road coordinates in tile\n",
    "        tile_contents = d_tile_contents[tile]\n",
    "\n",
    "        # Find pixel elements corresponding to roads\n",
    "        # Fill in matrix of values\n",
    "        pixel_mat = np.zeros((256,256))\n",
    "        for elem in tile_contents:\n",
    "            x = int(elem[1]*255)\n",
    "            y = int((1-elem[2])*255)\n",
    "            pixel_mat[y,x] = 1\n",
    "        d_road_pixels[tile] = pixel_mat\n",
    "        \n",
    "        #plt.spy(pixel_mat)\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4edfb96953f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ymargin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4350\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_collection\u001b[0;34m(self, collection, autolim)\u001b[0m\n\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mautolim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_datalim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_datalim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/collections.py\u001b[0m in \u001b[0;36mget_datalim\u001b[0;34m(self, transData)\u001b[0m\n\u001b[1;32m    207\u001b[0m             result = mpath.get_path_collection_extents(\n\u001b[1;32m    208\u001b[0m                 \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 offsets, transOffset.frozen())\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transformed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/matplotlib/path.py\u001b[0m in \u001b[0;36mget_path_collection_extents\u001b[0;34m(master_transform, paths, transforms, offsets, offset_transform)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \"\"\"\n\u001b[0;32m-> 1004\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No paths provided\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x0 = 95000\n",
    "y0 = 430000\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=11,ncols=11, figsize=(16,16))\n",
    "\n",
    "for ii in range(0,11):\n",
    "    for jj in range(0,11):\n",
    "        ll_x = x0 + ii*dx\n",
    "        ll_y = y0 + jj*dy\n",
    "        ur_x = ll_x + dx\n",
    "        ur_y = ll_y + dy\n",
    "        tile = \"{}_{}_{}_{}.jpg\".format(ll_x, ll_y, ur_x, ur_y)\n",
    "        filename = INPUT_FOLDER_TILES + tile        \n",
    "        tile_contents = d_tile_contents[tile]\n",
    "        \n",
    "        ax = axarr[10-jj, ii]\n",
    "        image = ndimage.imread(filename)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(rgb_image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        for elem in tile_contents:\n",
    "            color = dict_roadtype_to_color[elem[0]]\n",
    "            x = elem[1]*256\n",
    "            y = (1-elem[2])*256\n",
    "            ax.scatter(x,y,c=color,s=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# DK checks\n",
    "image = \"95000_430000_95200_430200.jpg\"\n",
    "filename = INPUT_FOLDER_TILES + image\n",
    "image_view = ndimage.imread(filename).astype(np.float32)\n",
    "plt.imshow(image_view)\n",
    "plt.show()\n",
    "print(image_view.shape)\n",
    "print(type(image_view))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = \"95000_430000_95200_430200.jpg\"\n",
    "test_matrix = d_road_pixels[image]\n",
    "plt.spy(test_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x0 = 95400\n",
    "y0 = 432000\n",
    "POINTS_PER_METER = 0\n",
    "\n",
    "fig, axarr = plt.subplots(nrows=11,ncols=11, figsize=(16,16))\n",
    "\n",
    "for ii in range(0,11):\n",
    "    for jj in range(0,11):\n",
    "        ll_x = x0 + ii*dx\n",
    "        ll_y = y0 + jj*dy\n",
    "        ur_x = ll_x + dx\n",
    "        ur_y = ll_y + dy\n",
    "        tile = \"{}_{}_{}_{}.jpg\".format(ll_x, ll_y, ur_x, ur_y)\n",
    "        filename = INPUT_FOLDER_TILES + tile\n",
    "        tile_contents = d_tile_contents[tile]\n",
    "        \n",
    "        ax = axarr[10-jj, ii]\n",
    "        image = ndimage.imread(filename)\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(rgb_image)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        for elem in tile_contents:\n",
    "            color = dict_roadtype_to_color[elem[0]]\n",
    "            x = elem[1]*256\n",
    "            y = (1-elem[2])*256\n",
    "            ax.scatter(x,y,c=color,s=10)\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4c. Some statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of roadtype G (Gemeente) there are 4963 tiles.\n",
      "Of roadtype W (Waterschap) there are 915 tiles.\n",
      "Of roadtype P (Provincie) there are 48 tiles.\n",
      "Of roadtype T (Andere wegbeheerder) there are 1 tiles.\n"
     ]
    }
   ],
   "source": [
    "for rtype in d_roadtype_tiles.keys():\n",
    "    roadtype = dict_roadtype[rtype]\n",
    "    no_tiles = len(d_roadtype_tiles[rtype])\n",
    "    print(\"Of roadtype {} ({}) there are {} tiles.\".format(rtype, roadtype, no_tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prepare dataset for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels1, labels2):\n",
    "    permutation = np.random.permutation(dataset.shape[0])\n",
    "    print(permutation.shape)\n",
    "    print(dataset.shape)\n",
    "    print(labels1.shape)\n",
    "    print(labels2.shape)\n",
    "    randomized_dataset = dataset[permutation, :, :, :]\n",
    "    randomized_labels1 = labels1[permutation, :]\n",
    "    randomized_labels2 = labels2[permutation]\n",
    "    return randomized_dataset, randomized_labels1, randomized_labels2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Added By Soumya : 5a. Split data into 4 tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(image, image_data, image_width, image_height, image_depth, split_factor):\n",
    "    start_x = 0\n",
    "    start_y = 0 \n",
    "    new_image_height = int(image_height/split_factor)\n",
    "    new_image_width = int(image_width/split_factor)\n",
    "    stride_x = new_image_width\n",
    "    stride_y = new_image_height\n",
    "    \n",
    "    tiles_x = int(split_factor/2)\n",
    "    tiles_y = int(split_factor/2)\n",
    "\n",
    "    split_images = np.ndarray(shape=(split_factor, new_image_width, \\\n",
    "                            new_image_height, image_depth), dtype=np.float32)\n",
    "    split_labels = np.ndarray(shape=(split_factor, new_image_width, \\\n",
    "                            new_image_height), dtype=np.float32)\n",
    "    labels_roadpixel = d_road_pixels[image]\n",
    "    \n",
    "    for i in range(tiles_x):\n",
    "        for j in range(tiles_y):\n",
    "            split_images[i+j] = image_data[start_x:start_x+stride_x, start_y:start_y+stride_y, :]\n",
    "            split_labels[i+j] = labels_roadpixel[start_x:start_x+stride_x, start_y:start_y+stride_y]\n",
    "            start_x = start_x + stride_x\n",
    "        start_y = start_y + stride_y\n",
    "        start_x = 0\n",
    "    return split_images, split_labels\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images have been loaded.\n",
      "1000 images have been loaded.\n",
      "2000 images have been loaded.\n",
      "3000 images have been loaded.\n",
      "4000 images have been loaded.\n",
      "5000 images have been loaded.\n",
      "6000 images have been loaded.\n",
      "7000 images have been loaded.\n",
      "8000 images have been loaded.\n",
      "9000 images have been loaded.\n",
      "(40000,)\n",
      "(40000, 4096)\n",
      "(40000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "image_width = 256\n",
    "image_height = 256\n",
    "image_depth = 3\n",
    "total_no_images = 10000\n",
    "split_factor = 4\n",
    "\n",
    "new_image_height = int(image_height/split_factor)\n",
    "new_image_width = int(image_width/split_factor)\n",
    "new_total_images = total_no_images*split_factor\n",
    "\n",
    "image_files = os.listdir(INPUT_FOLDER_TILES)\n",
    "\n",
    "dataset = np.ndarray(shape=(new_total_images, new_image_width, \\\n",
    "                            new_image_height, image_depth), dtype=np.float32)\n",
    "labels_roadtype = []\n",
    "labels_roadpresence = np.ndarray(new_total_images, dtype=np.float32)\n",
    "labels_roadpixel = np.zeros((new_total_images, new_image_width * new_image_height))\n",
    "labels_filename = []\n",
    "\n",
    "for counter, image in enumerate(image_files):\n",
    "    filename = INPUT_FOLDER_TILES + image\n",
    "    image_data = ndimage.imread(filename).astype(np.float32)\n",
    "    split_images, split_labels_roadpixel = split_data(image, image_data, image_width, image_height, image_depth, split_factor)\n",
    "    for i in range(split_factor):\n",
    "        labels_filename.append(image+\"_\"+str(i))           \n",
    "         \n",
    "        if image in list(d_tile_contents.keys()):\n",
    "            tile_contents = d_tile_contents[image]\n",
    "            roadtypes = sorted(list(set([elem[0] for elem in tile_contents])))\n",
    "            roadtype = \"_\".join(roadtypes)\n",
    "            labels_roadpresence[counter*split_factor + i] = 1\n",
    "        else:\n",
    "            roadtype = ''\n",
    "            labels_roadpresence[counter*split_factor + i] = 0\n",
    "            \n",
    "        labels_roadpixel[counter*split_factor + i] = split_labels_roadpixel[i].flatten()\n",
    "        labels_roadtype.append(roadtype)\n",
    "        dataset[counter*split_factor + i, :, :] = split_images[i]\n",
    "    if counter % 1000 == 0:\n",
    "        print(\"{} images have been loaded.\".format(counter))\n",
    "\n",
    "print(labels_roadpresence.shape)\n",
    "print(labels_roadpixel.shape)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing dataset...\n",
      "(40000,)\n",
      "(40000, 64, 64, 3)\n",
      "(40000, 4096)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "labels_filename = np.array(labels_filename)\n",
    "print(\"Randomizing dataset...\")\n",
    "dataset, labels_roadpixels, labels_filename = randomize(dataset, labels_roadpixel, labels_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "saved dataset to ./data/sattelite_dataset_pixel.pickle\n"
     ]
    }
   ],
   "source": [
    "# Split into train/validation/test sets\n",
    "start_train_dataset = 0\n",
    "start_valid_dataset = 32000\n",
    "start_test_dataset = 36000\n",
    "total_no_images = 40000\n",
    "\n",
    "output_pickle_file = './data/sattelite_dataset_pixel.pickle'\n",
    "\n",
    "f = open(output_pickle_file, 'wb')\n",
    "save = {\n",
    "'train_dataset': dataset[start_train_dataset:start_valid_dataset,:,:,:],\n",
    "'train_labels_roadpixels': labels_roadpixels[start_train_dataset:start_valid_dataset,:],\n",
    "'train_labels_filename': labels_filename[start_train_dataset:start_valid_dataset],\n",
    "'valid_dataset': dataset[start_valid_dataset:start_test_dataset,:,:,:],\n",
    "'valid_labels_roadpixels': labels_roadpixels[start_valid_dataset:start_test_dataset,:],\n",
    "'valid_labels_filename': labels_filename[start_valid_dataset:start_test_dataset],\n",
    "'test_dataset': dataset[start_test_dataset:total_no_images,:,:,:],\n",
    "'test_labels_roadpixels': labels_roadpixels[start_test_dataset:total_no_images,:],\n",
    "'test_labels_filename': labels_filename[start_test_dataset:total_no_images]\n",
    "}\n",
    "pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "print(\"\\nsaved dataset to {}\".format(output_pickle_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The Convolutional neural network part (Using vggnet for pixel level classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from cnn_models.vggnet16pixel import * \n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = './data/sattelite_dataset.pickle'\n",
    "f = open(pickle_file, 'rb')\n",
    "save = pickle.load(f)\n",
    "\n",
    "train_dataset = save['train_dataset'].astype(dtype = np.float32)\n",
    "train_labels = save['train_labels_roadpresence'].astype(dtype = np.float32)\n",
    "valid_dataset = save['valid_dataset'].astype(dtype = np.float32)\n",
    "valid_labels = save['valid_labels_roadpresence'].astype(dtype = np.float32)\n",
    "test_dataset = save['test_dataset'].astype(dtype = np.float32)\n",
    "test_labels = save['test_labels_roadpresence'].astype(dtype = np.float32)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_labels = len(np.unique(train_labels))\n",
    "#print(np.unique(train_labels))\n",
    "image_width = 64\n",
    "image_height = 64\n",
    "image_depth = 3\n",
    "num_steps = 20\n",
    "display_step = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "lambda_loss_amount = 0.0015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING WITH SATTELITE\n",
      "<tf.Variable 'Variable_31:0' shape=(4096,) dtype=float32_ref>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32768 and 2048 for 'MatMul' (op: 'MatMul') with input shapes: [5,32768], [2048,4096].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32768 and 2048 for 'MatMul' (op: 'MatMul') with input shapes: [5,32768], [2048,4096].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-6d40159321d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vggnet16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#4. then we compute the softmax cross entropy between the logits and the (actual) labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/roads_detection_old/cnn_models/vggnet16pixel.py\u001b[0m in \u001b[0;36mmodel_vggnet16\u001b[0;34m(data, variables)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mflat_layer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mflatten_tf_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer13_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mlayer14_fccd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w14'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b14'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0mlayer14_actv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer14_fccd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mlayer14_drop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer14_actv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2122\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4277\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4278\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4280\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1732\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1733\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1734\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1735\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32768 and 2048 for 'MatMul' (op: 'MatMul') with input shapes: [5,32768], [2048,4096]."
     ]
    }
   ],
   "source": [
    "train_accuracies, test_accuracies, valid_accuracies = [], [], []\n",
    " \n",
    "print(\"STARTING WITH SATTELITE\")\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    #1) First we put the input data in a tensorflow friendly form. \n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape = (batch_size, image_width * image_height))\n",
    "    tf_test_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))\n",
    "    tf_test_labels = tf.placeholder(tf.float32, shape = (batch_size, image_width * image_height))\n",
    "    tf_valid_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_width, image_height, image_depth))\n",
    "    tf_valid_labels = tf.placeholder(tf.float32, shape = (batch_size, image_width * image_height))\n",
    " \n",
    "    #2) Then, the weight matrices and bias vectors are initialized\n",
    "    variables = variables_vggnet16()\n",
    "    print(variables[\"b16\"])\n",
    "    #3. The model used to calculate the logits (predicted labels)\n",
    "    model = model_vggnet16\n",
    "    \n",
    "    logits = model(tf_train_dataset, variables)\n",
    " \n",
    "    #4. then we compute the softmax cross entropy between the logits and the (actual) labels\n",
    "    l2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf_train_labels)) + l2\n",
    " \n",
    "    #learning_rate = tf.train.exponential_decay(0.05, global_step, 1000, 0.85, staircase=True)\n",
    "    #5. The optimizer is used to calculate the gradients of the loss function \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    " \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.sigmoid(logits)\n",
    "    test_prediction = tf.nn.sigmoid(model(tf_test_dataset, variables))\n",
    "    valid_prediction = tf.nn.sigmoid(model(tf_valid_dataset, variables))\n",
    " \n",
    " \n",
    "with tf.Session(graph=graph) as session:\n",
    "    test_counter = 0\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized with learning_rate', learning_rate, \" model \")\n",
    "    for step in range(num_steps):\n",
    "        #Since we are using stochastic gradient descent, we are selecting  small batches from the training dataset,\n",
    "        #and training the convolutional neural network each time with a batch. \n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :,  :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        \n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        train_accuracy = accuracy(predictions, batch_labels)\n",
    "        train_accuracies.append(train_accuracy)\n",
    " \n",
    "        if step % display_step == 0:\n",
    "            offset2 = (test_counter * batch_size) % (test_labels.shape[0] - batch_size)\n",
    "            test_dataset_batch = test_dataset[offset2:(offset2 + batch_size), :, :]\n",
    "            test_labels_batch = test_labels[offset2:(offset2 + batch_size), :]\n",
    "            feed_dict2 = {tf_test_dataset : test_dataset_batch, tf_test_labels : test_labels_batch}\n",
    "            \n",
    "            test_prediction_ = session.run(test_prediction, feed_dict=feed_dict2)\n",
    "            test_accuracy = accuracy(test_prediction_, test_labels_batch)\n",
    "            test_accuracies.append(test_accuracy)\n",
    " \n",
    "            valid_dataset_batch = valid_dataset[offset2:(offset2 + batch_size), :, :]\n",
    "            valid_labels_batch = valid_labels[offset2:(offset2 + batch_size), :]\n",
    "            feed_dict3 = {tf_valid_dataset : valid_dataset_batch, tf_valid_labels : valid_labels_batch}\n",
    "            \n",
    "            valid_prediction_ = session.run(valid_prediction, feed_dict=feed_dict3)\n",
    "            valid_accuracy = accuracy(valid_prediction_, valid_labels_batch)\n",
    "            valid_accuracies.append(valid_accuracy)\n",
    " \n",
    "            message = \"step {:04d} : loss is {:06.2f}, accuracy on training set {:02.2f} %, accuracy on test set {:02.2f} accuracy on valid set {:02.2f} %\".format(step, l, train_accuracy, test_accuracy, valid_accuracy)\n",
    "            print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
